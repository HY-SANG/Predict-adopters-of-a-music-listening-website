{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize']=(14,6)\n",
    "# import necessary libraries and specify that graphs should be plotted inline.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score,StratifiedKFold, KFold\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn import feature_selection\n",
    "from sklearn import datasets, tree, linear_model, svm, cross_validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score, make_scorer, roc_auc_score, roc_curve\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.feature_selection import plot_sequential_feature_selection as plot_sfs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from __future__ import print_function\n",
    "import subprocess\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "sm = SMOTE(kind='regular')\n",
    "os.chdir('C:\\Users\\Pranathi\\Desktop\\MSBA\\Fall\\Predictive analytics\\Assignment 5\\HW5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapping(y):\n",
    "    if y>= 0.7:\n",
    "        return(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Cross-validation and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Functions\n",
    "def over_cross(clf,X,y,sm):\n",
    "    scores_oc = []\n",
    "    kfolds_oc = cross_validation.StratifiedKFold(y, n_folds=5, shuffle=True, random_state=0)\n",
    "    for train_index, test_index in kfolds_oc:\n",
    "        X_train_oc, X_test_oc = X[train_index], X[test_index]\n",
    "        y_train_oc, y_test_oc = y[train_index], y[test_index]\n",
    "        X_train_oc, y_train_oc = sm.fit_sample(X_train_oc, y_train_oc)\n",
    "        clf.fit(X_train_oc, y_train_oc)\n",
    "        prediction_oc=clf.predict(X_test_oc)\n",
    "        scores_oc.append(f1_score(y_test_oc, prediction_oc,pos_label=1))\n",
    "    return np.mean(scores_oc)\n",
    "\n",
    "def over_cross_probability(clf,X,y,sm,prob):\n",
    "    scores_oc = []\n",
    "    kfolds_oc = cross_validation.StratifiedKFold(y, n_folds=5, shuffle=True, random_state=0)\n",
    "    for train_index, test_index in kfolds_oc:\n",
    "        X_train_oc, X_test_oc = X[train_index], X[test_index]\n",
    "        y_train_oc, y_test_oc = y[train_index], y[test_index]\n",
    "        X_train_oc, y_train_oc = sm.fit_sample(X_train_oc, y_train_oc)\n",
    "        clf.fit(X_train_oc, y_train_oc)\n",
    "        prediction_prob_oc=clf.predict_proba(X_test_oc)[:,1]\n",
    "        new_preds_oc = [0 if x <prob else 1 for x in prediction_prob_oc]\n",
    "        scores_oc.append(f1_score(y_test_oc, new_preds_oc,pos_label=1))\n",
    "    return np.mean(scores_oc)\n",
    "\n",
    "def pred_prob(clf,x_pred_test,y_pred_test,prob):\n",
    "    prediction_prob_oc=clf.predict_proba(x_pred_test)[:,1]\n",
    "    new_prob_preds = [0 if x <prob else 1 for x in prediction_prob_oc]\n",
    "    return f1_score(y_pred_test, new_prob_preds,pos_label=1)\n",
    "\n",
    "\n",
    "def cust_over_cm(clf,x_pred_test,y_pred_test,prob,sm):\n",
    "    scores_oc = []\n",
    "    columns=[\"Predictions\",\"Actual\"]\n",
    "    df_conf = pd.DataFrame( columns=columns)\n",
    "    df_conf = df_conf.fillna(0)  \n",
    "    scores_oc = []\n",
    "    kfolds_oc = cross_validation.StratifiedKFold(y, n_folds=5, shuffle=True, random_state=0)\n",
    "    for train_index, test_index in kfolds_oc:\n",
    "        X_train_oc, X_test_oc = X[train_index], X[test_index]\n",
    "        y_train_oc, y_test_oc = y[train_index], y[test_index]\n",
    "        X_train_oc, y_train_oc = sm.fit_sample(X_train_oc, y_train_oc)\n",
    "        clf.fit(X_train_oc, y_train_oc)\n",
    "        prediction_prob_oc=clf.predict_proba(X_test_oc)[:,1]\n",
    "        new_preds_oc = [0 if x <prob else 1 for x in prediction_prob_oc]\n",
    "        df=pd.DataFrame({'Predictions':new_preds_oc, 'Actual':y_test_oc})\n",
    "        df_conf=df_conf.append(df)\n",
    "        scores_oc.append(f1_score(y_test_oc, new_preds_oc,pos_label=1))\n",
    "    return np.mean(scores_oc),df_conf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "music=pd.read_csv(\"Train.csv\")\n",
    "train_music=pd.read_csv(\"Train.csv\")\n",
    "test_music=pd.read_csv(\"Test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>male</th>\n",
       "      <th>friend_cnt</th>\n",
       "      <th>avg_friend_age</th>\n",
       "      <th>avg_friend_male</th>\n",
       "      <th>friend_country_cnt</th>\n",
       "      <th>subscriber_friend_cnt</th>\n",
       "      <th>songsListened</th>\n",
       "      <th>lovedTracks</th>\n",
       "      <th>posts</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_songsListened</th>\n",
       "      <th>delta_lovedTracks</th>\n",
       "      <th>delta_posts</th>\n",
       "      <th>delta_playlists</th>\n",
       "      <th>delta_shouts</th>\n",
       "      <th>tenure</th>\n",
       "      <th>good_country</th>\n",
       "      <th>delta_good_country</th>\n",
       "      <th>user_id</th>\n",
       "      <th>adopter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37804.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15955.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>802.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31441.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  male  friend_cnt  avg_friend_age  avg_friend_male  \\\n",
       "0  24.0   0.0        20.0       26.333333         0.777778   \n",
       "1  29.0   1.0        12.0       26.900000         0.818182   \n",
       "2  22.0   0.0         4.0       21.000000         1.000000   \n",
       "3  27.0   0.0         1.0       29.000000         1.000000   \n",
       "4  22.0   1.0         4.0       21.250000         0.750000   \n",
       "\n",
       "   friend_country_cnt  subscriber_friend_cnt  songsListened  lovedTracks  \\\n",
       "0                 6.0                    0.0        37804.0          4.0   \n",
       "1                 6.0                    1.0        15955.0         19.0   \n",
       "2                 2.0                    0.0        31441.0          7.0   \n",
       "3                 1.0                    0.0            0.0          0.0   \n",
       "4                 1.0                    0.0          774.0          0.0   \n",
       "\n",
       "   posts   ...     delta_songsListened  delta_lovedTracks  delta_posts  \\\n",
       "0   20.0   ...                    54.0                0.0          0.0   \n",
       "1    4.0   ...                   802.0                0.0          0.0   \n",
       "2    0.0   ...                     0.0                0.0          0.0   \n",
       "3    0.0   ...                     0.0                0.0          0.0   \n",
       "4    0.0   ...                     0.0                0.0          0.0   \n",
       "\n",
       "   delta_playlists  delta_shouts  tenure  good_country  delta_good_country  \\\n",
       "0              0.0           0.0    79.0           0.0                 0.0   \n",
       "1              0.0           1.0    80.0           0.0                 0.0   \n",
       "2              0.0           0.0    53.0           0.0                 0.0   \n",
       "3              0.0           0.0    59.0           0.0                 0.0   \n",
       "4              0.0           0.0    60.0           0.0                 0.0   \n",
       "\n",
       "   user_id  adopter  \n",
       "0     10.0        0  \n",
       "1     58.0        0  \n",
       "2     72.0        0  \n",
       "3    121.0        0  \n",
       "4    137.0        0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_music.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X = music.iloc[0:,:25].values # we only take the first two features in order to easily visualize the results. \n",
    "                      # We could avoid this ugly slicing by using a two-dim dataset\n",
    "y = music.adopter.values\n",
    "\n",
    "test_X = test_music.iloc[0:,:25].values # we only take the first two features in order to easily visualize the results. \n",
    "                      # We could avoid this ugly slicing by using a two-dim dataset\n",
    "\n",
    "df_user = pd.DataFrame(test_music[\"user_id\"], columns=['user_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Normalize train and test together\n",
    "train_music['flag']=1\n",
    "test_music['flag']=0\n",
    "train_music.drop('adopter', axis=1, inplace=True)\n",
    "\n",
    "combine=train_music.append(test_music)\n",
    "combine_norm = min_max_scaler.fit_transform(combine)\n",
    "\n",
    "df_combine_norm=pd.DataFrame(combine_norm)\n",
    "train_norm=df_combine_norm[df_combine_norm[26]==1]\n",
    "test_norm=df_combine_norm[df_combine_norm[26]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>male</th>\n",
       "      <th>friend_cnt</th>\n",
       "      <th>avg_friend_age</th>\n",
       "      <th>avg_friend_male</th>\n",
       "      <th>friend_country_cnt</th>\n",
       "      <th>subscriber_friend_cnt</th>\n",
       "      <th>songsListened</th>\n",
       "      <th>lovedTracks</th>\n",
       "      <th>posts</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_songsListened</th>\n",
       "      <th>delta_lovedTracks</th>\n",
       "      <th>delta_posts</th>\n",
       "      <th>delta_playlists</th>\n",
       "      <th>delta_shouts</th>\n",
       "      <th>tenure</th>\n",
       "      <th>good_country</th>\n",
       "      <th>delta_good_country</th>\n",
       "      <th>user_id</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37804.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15955.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>802.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31441.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  male  friend_cnt  avg_friend_age  avg_friend_male  \\\n",
       "0  24.0   0.0        20.0       26.333333         0.777778   \n",
       "1  29.0   1.0        12.0       26.900000         0.818182   \n",
       "2  22.0   0.0         4.0       21.000000         1.000000   \n",
       "3  27.0   0.0         1.0       29.000000         1.000000   \n",
       "4  22.0   1.0         4.0       21.250000         0.750000   \n",
       "\n",
       "   friend_country_cnt  subscriber_friend_cnt  songsListened  lovedTracks  \\\n",
       "0                 6.0                    0.0        37804.0          4.0   \n",
       "1                 6.0                    1.0        15955.0         19.0   \n",
       "2                 2.0                    0.0        31441.0          7.0   \n",
       "3                 1.0                    0.0            0.0          0.0   \n",
       "4                 1.0                    0.0          774.0          0.0   \n",
       "\n",
       "   posts  ...   delta_songsListened  delta_lovedTracks  delta_posts  \\\n",
       "0   20.0  ...                  54.0                0.0          0.0   \n",
       "1    4.0  ...                 802.0                0.0          0.0   \n",
       "2    0.0  ...                   0.0                0.0          0.0   \n",
       "3    0.0  ...                   0.0                0.0          0.0   \n",
       "4    0.0  ...                   0.0                0.0          0.0   \n",
       "\n",
       "   delta_playlists  delta_shouts  tenure  good_country  delta_good_country  \\\n",
       "0              0.0           0.0    79.0           0.0                 0.0   \n",
       "1              0.0           1.0    80.0           0.0                 0.0   \n",
       "2              0.0           0.0    53.0           0.0                 0.0   \n",
       "3              0.0           0.0    59.0           0.0                 0.0   \n",
       "4              0.0           0.0    60.0           0.0                 0.0   \n",
       "\n",
       "   user_id  flag  \n",
       "0     10.0     1  \n",
       "1     58.0     1  \n",
       "2     72.0     1  \n",
       "3    121.0     1  \n",
       "4    137.0     1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_music.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_norm = StandardScaler().fit_transform(X)\n",
    "#X_norm = min_max_scaler.fit_transform(X)\n",
    "X_norm = train_music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Penalty','C','CV F Measure','Test F Measure']\n",
    "df_logistic = pd.DataFrame( columns=columns)\n",
    "df_logistic = df_logistic.fillna(0) \n",
    "# Set regularization parameter\n",
    "prob=0.5\n",
    "#sm = SMOTEENN()\n",
    "#sm = SMOTETomek()\n",
    "sm= SMOTE(ratio = 0.4, kind = 'borderline1', random_state = 0)\n",
    "for i, C in enumerate((100, 1, 0.01)):\n",
    "    # turn down tolerance for short training time\n",
    "    clf_l1_LR = LogisticRegression(C=C, penalty='l1', tol=0.01)\n",
    "    clf_l2_LR = LogisticRegression(C=C, penalty='l2', tol=0.01)\n",
    "    clf_l1_LR_cross = LogisticRegression(C=C, penalty='l1', tol=0.01)\n",
    "    clf_l2_LR_cross = LogisticRegression(C=C, penalty='l2', tol=0.01)\n",
    "    clf_l1_LR.fit(X_train, y_train)\n",
    "    clf_l2_LR.fit(X_train, y_train)\n",
    "\n",
    "    prediction=clf_l1_LR.predict(X_test)\n",
    "    df = pd.DataFrame([['L1',C,over_cross_probability(clf_l1_LR,X_train,y_train,sm,prob),pred_prob(clf_l1_LR,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "\n",
    "    df_logistic=df_logistic.append(df)\n",
    "    prediction=clf_l2_LR.predict(X_test)\n",
    "    df = pd.DataFrame([['L2',C,over_cross_probability(clf_l2_LR,X_train,y_train,sm,prob),pred_prob(clf_l2_LR,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "\n",
    "    df_logistic=df_logistic.append(df)\n",
    "    df_logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.034860</td>\n",
       "      <td>0.034697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.046352</td>\n",
       "      <td>0.041413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.073812</td>\n",
       "      <td>0.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.091331</td>\n",
       "      <td>0.097576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.101777</td>\n",
       "      <td>0.112636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.110661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.103715</td>\n",
       "      <td>0.106047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.094848</td>\n",
       "      <td>0.094388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.076428</td>\n",
       "      <td>0.078902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability  CV F Measure  Test F Measure\n",
       "0          0.1      0.034860        0.034697\n",
       "0          0.2      0.046352        0.041413\n",
       "0          0.3      0.073812        0.068900\n",
       "0          0.4      0.091331        0.097576\n",
       "0          0.5      0.101777        0.112636\n",
       "0          0.6      0.105295        0.110661\n",
       "0          0.7      0.103715        0.106047\n",
       "0          0.8      0.094848        0.094388\n",
       "0          0.9      0.076428        0.078902"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_norm = StandardScaler().fit_transform(X)\n",
    "X_norm = train_music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_logistic = pd.DataFrame( columns=columns)\n",
    "df_logistic = df_logistic.fillna(0) \n",
    "sm = SMOTE(0.4,kind = 'borderline2',random_state = 1)\n",
    "for prob in arange(0.1,1,0.1):\n",
    "    clf = LogisticRegression(C=100, penalty='l1', tol=0.01)\n",
    "    df = pd.DataFrame([[prob,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_logistic=df_logistic.append(df)\n",
    "    \n",
    "df_logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_norm = StandardScaler().fit_transform(X)\n",
    "X_norm = train_music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_logistic = pd.DataFrame( columns=columns)\n",
    "df_logistic = df_logistic.fillna(0) \n",
    "sm = SMOTE(0.6,kind = 'svm',random_state = 1)\n",
    "for prob in arange(0.1,1,0.1):\n",
    "    clf = LogisticRegression(C=100, penalty='l1', tol=0.01)\n",
    "    df = pd.DataFrame([[prob,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_logistic=df_logistic.append(df)\n",
    "    \n",
    "df_logistic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.109261</td>\n",
       "      <td>0.109848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability  CV F Measure  Test F Measure\n",
       "0          0.8      0.109261        0.109848"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_norm = StandardScaler().fit_transform(X)\n",
    "X_norm = train_norm.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_logistic = pd.DataFrame( columns=columns)\n",
    "df_logistic = df_logistic.fillna(0) \n",
    "sm = SMOTEENN()\n",
    "#sm = SMOTETomek()\n",
    "for prob in arange(0.8,0.9,0.1):\n",
    "    clf = LogisticRegression(C=100, penalty='l1', tol=0.01)\n",
    "    df = pd.DataFrame([[prob,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_logistic=df_logistic.append(df)\n",
    "    \n",
    "df_logistic\n",
    "\n",
    "#0.11007\n",
    "#output generated using 0.9 i think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate Output file\n",
    "X_val = test_norm.iloc[0:,:25].values\n",
    "X_norm = train_norm.iloc[0:,:25].values\n",
    "X_train=X_norm\n",
    "y_train=y\n",
    "sm = SMOTEENN()\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "clf = LogisticRegression(C=100, penalty='l1', tol=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions=clf.predict_proba(X_val)[:,1]\n",
    "new_predictions = [0 if x <0.7 else 1 for x in predictions]\n",
    "df_out = pd.DataFrame(new_predictions, columns=['prediction(adopter)'])\n",
    "df_out=pd.concat([df_user,df_out], axis=1)\n",
    "df_out.to_csv(\"submit_logistic_kk.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_val = test_music.iloc[0:,:25].values\n",
    "X_train = music.iloc[0:,:25].values\n",
    "y_train = y\n",
    "\n",
    "sm= SMOTE(ratio = 0.4, kind = 'borderline1', random_state = 0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "\n",
    "predictions=clf.predict(X_val)\n",
    "\n",
    "#new_predictions = [0 if x <0.8 else 1 for x in predictions]\n",
    "df_out = pd.DataFrame(predictions, columns=['prediction(adopter)'])\n",
    "df_out=pd.concat([df_user,df_out], axis=1)\n",
    "df_out.to_csv(\"submit_gb.csv\",sep=\",\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checking oversampling ratio\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['ratio','0','1']\n",
    "\n",
    "b= pd.DataFrame()\n",
    "for i in arange(0.4,0.8,0.1):\n",
    "        sm= SMOTE(ratio = i, kind = 'borderline1', random_state = 0)\n",
    "        X_train_oc, y_train_oc = sm.fit_sample(X_train, y_train)\n",
    "        df = pd.DataFrame({'flag' : y_train_oc})\n",
    "        x = df.groupby(['flag']).size()\n",
    "        #a = pd.DataFrame({'ratio': i , '0': x[0], '1': x[1]})\n",
    "        a = df = pd.DataFrame([[i,x[0],x[1]]],columns=columns)\n",
    "        b = b.append(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Decision Trees for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0.066664</td>\n",
       "      <td>0.050154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  CV F Measure  Test F Measure\n",
       "0  13      0.066664        0.050154"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_norm = train_norm.iloc[0:,:25].values\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['k','CV F Measure','Test F Measure']\n",
    "\n",
    "for k in arange(3,15,2):\n",
    "        sm= SMOTE(ratio = i , kind = 'borderline1', random_state = 0)\n",
    "        \n",
    "        clf = BaggingClassifier(base_estimator=neighbors.KNeighborsClassifier(k), n_estimators= 10,\\\n",
    "                           random_state= 0)\n",
    "        df = pd.DataFrame([[k,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "df     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024758</td>\n",
       "      <td>0.021798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CV F Measure  Test F Measure\n",
       "0      0.024758        0.021798"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_norm = train_norm.iloc[0:,:25].values\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['n_estimators' ,'ratio','CV F Measure','Test F Measure']\n",
    "\n",
    "for n_estimators in arange(10,100,10):\n",
    "     for i in arange(0.4,0.8,0.1):\n",
    "        sm= SMOTE(ratio = i , kind = 'borderline1', random_state = 0)\n",
    "        \n",
    "        clf = BaggingClassifier(base_estimator=neighbors.KNeighborsClassifier(), n_estimators= n_estimators,\\\n",
    "                           random_state= 0)\n",
    "        df = pd.DataFrame([[n_estimators,i,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trees</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.013037</td>\n",
       "      <td>0.028329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.018182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.025078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.024922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.012579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.018809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.012579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trees  CV F Measure  Test F Measure\n",
       "0    5.0      0.013037        0.028329\n",
       "0    6.0      0.008979        0.018182\n",
       "0    7.0      0.006287        0.025078\n",
       "0    8.0      0.001575        0.024922\n",
       "0    9.0      0.000000        0.012739\n",
       "0   10.0      0.003125        0.012579\n",
       "0   11.0      0.004775        0.012461\n",
       "0   12.0      0.004749        0.018809\n",
       "0   13.0      0.001575        0.012579\n",
       "0   14.0      0.001606        0.006329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_norm = StandardScaler().fit_transform(X)\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Trees','CV F Measure','Test F Measure']\n",
    "df_dt = pd.DataFrame( columns=columns)\n",
    "df_dt = df_dt.fillna(0) \n",
    "sm = SMOTEENN()\n",
    "cart = DecisionTreeClassifier()\n",
    "prob=0.8\n",
    "#sm = SMOTETomek()\n",
    "for num_trees in arange(5,15,1):\n",
    "    clf = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=0)\n",
    "    df = pd.DataFrame([[num_trees,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_dt=df_dt.append(df)\n",
    "    \n",
    "df_dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trees</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Extra</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trees  CV F Measure  Test F Measure\n",
       "0  Extra           0.0             0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "num_trees = 20\n",
    "max_features = 15\n",
    "columns=['Trees','CV F Measure','Test F Measure']\n",
    "sm = SMOTEENN()\n",
    "cart = DecisionTreeClassifier()\n",
    "prob=0.8\n",
    "clf = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features,random_state=0)\n",
    "df = pd.DataFrame([['Extra',over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attribute Selection and Knn\n",
    "\n",
    "columns=['attr','k','CV F Measure','Test F Measure']\n",
    "X_norm = train_norm.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "df_k = pd.DataFrame( columns=columns)\n",
    "df_k = df_k.fillna(0) \n",
    "prob=0.5\n",
    "for attr in range(1,26):\n",
    "    for k in range(1,30):\n",
    "        model = feature_selection.SelectKBest(score_func=feature_selection.f_classif,\\\n",
    "                                      k=attr)\n",
    "        results=model.fit(X_train,y_train)\n",
    "        X_subset = X_train[:, results.get_support()]\n",
    "        X_subtest = X_test[:, results.get_support()]\n",
    "        clf = neighbors.KNeighborsClassifier(k)\n",
    "        df = pd.DataFrame([[attr,k,over_cross_probability(clf,X_subset,y_train,sm,prob),pred_prob(clf,X_subtest,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "        df_k=df_k.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attr</th>\n",
       "      <th>k</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.079487</td>\n",
       "      <td>0.077580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.079275</td>\n",
       "      <td>0.080144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.078780</td>\n",
       "      <td>0.068154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.078518</td>\n",
       "      <td>0.077535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.078277</td>\n",
       "      <td>0.067082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.078065</td>\n",
       "      <td>0.081400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>0.069307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.077712</td>\n",
       "      <td>0.072581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.077648</td>\n",
       "      <td>0.065427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.077373</td>\n",
       "      <td>0.072646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   attr     k  CV F Measure  Test F Measure\n",
       "0   2.0  28.0      0.079487        0.077580\n",
       "0   2.0  22.0      0.079275        0.080144\n",
       "0   3.0   7.0      0.078780        0.068154\n",
       "0   2.0  25.0      0.078518        0.077535\n",
       "0   3.0   8.0      0.078277        0.067082\n",
       "0   2.0  24.0      0.078065        0.081400\n",
       "0   3.0   9.0      0.077746        0.069307\n",
       "0   2.0  27.0      0.077712        0.072581\n",
       "0   3.0  15.0      0.077648        0.065427\n",
       "0   3.0   5.0      0.077373        0.072646"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_k.sort_values(by=\"CV F Measure\",ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.090877</td>\n",
       "      <td>0.094862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.091163</td>\n",
       "      <td>0.088847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.086729</td>\n",
       "      <td>0.085590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.094517</td>\n",
       "      <td>0.083588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.078263</td>\n",
       "      <td>0.077333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.084028</td>\n",
       "      <td>0.083650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.070069</td>\n",
       "      <td>0.047794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.054333</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.031323</td>\n",
       "      <td>0.017045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability  CV F Measure  Test F Measure\n",
       "0          0.1      0.090877        0.094862\n",
       "0          0.2      0.091163        0.088847\n",
       "0          0.3      0.086729        0.085590\n",
       "0          0.4      0.094517        0.083588\n",
       "0          0.5      0.078263        0.077333\n",
       "0          0.6      0.084028        0.083650\n",
       "0          0.7      0.070069        0.047794\n",
       "0          0.8      0.054333        0.060120\n",
       "0          0.9      0.031323        0.017045"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability for knn\n",
    "X_norm = train_norm.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_knn_prob = pd.DataFrame( columns=columns)\n",
    "df_knn_prob = df_knn_prob.fillna(0) \n",
    "sm = SMOTEENN(0.6,random_state = 0)\n",
    "clf = neighbors.KNeighborsClassifier(28)\n",
    "model = feature_selection.SelectKBest(score_func=feature_selection.f_classif,\\\n",
    "                                      k=2)\n",
    "results=model.fit(X_train,y_train)\n",
    "X_subset = X_train[:, results.get_support()]\n",
    "X_subtest = X_test[:, results.get_support()]\n",
    "\n",
    "for prob in arange(0.1,1,0.1):\n",
    "    df = pd.DataFrame([[prob,over_cross_probability(clf,X_subset,y_train,sm,prob),pred_prob(clf,X_subtest,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_knn_prob=df_knn_prob.append(df)\n",
    "    \n",
    "df_knn_prob\n",
    "#0.92 probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.115097</td>\n",
       "      <td>0.134003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.113544</td>\n",
       "      <td>0.126872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.118974</td>\n",
       "      <td>0.123142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.112010</td>\n",
       "      <td>0.118609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>0.100645</td>\n",
       "      <td>0.125683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70.0</td>\n",
       "      <td>0.093806</td>\n",
       "      <td>0.129241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.086712</td>\n",
       "      <td>0.118616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  CV F Measure  Test F Measure\n",
       "0          20.0      0.115097        0.134003\n",
       "0          30.0      0.113544        0.126872\n",
       "0          40.0      0.118974        0.123142\n",
       "0          50.0      0.112010        0.118609\n",
       "0          60.0      0.100645        0.125683\n",
       "0          70.0      0.093806        0.129241\n",
       "0          80.0      0.086712        0.118616"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['n_estimators','CV F Measure','Test F Measure']\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "df_gb = pd.DataFrame( columns=columns)\n",
    "df_gb = df_gb.fillna(0) \n",
    "prob=0.5\n",
    "for n_estimators in arange(20,90,10):\n",
    "    sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)    prob=0.5\n",
    "    params = {'n_estimators': n_estimators,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, 'min_samples_leaf':50,\\\n",
    "              'max_depth':8, 'max_features':'sqrt', 'min_samples_split': 500}\n",
    "    clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "    df = pd.DataFrame([[n_estimators,over_cross_probability(clf,X_train,y_train,sm,prob),\\\n",
    "                            pred_prob(clf,X_test,y_test,prob)]],columns=columns)\n",
    "    df_gb=df_gb.append(df)\n",
    "df_gb\n",
    "#n-estimators = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.116383</td>\n",
       "      <td>0.130370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.113372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.110576</td>\n",
       "      <td>0.109705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.106242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.101381</td>\n",
       "      <td>0.119581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.100746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.086054</td>\n",
       "      <td>0.117424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.084912</td>\n",
       "      <td>0.095057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.084624</td>\n",
       "      <td>0.104247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.083532</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_samples_split  CV F Measure  Test F Measure\n",
       "0        5.0             1000.0      0.116383        0.130370\n",
       "0        5.0              200.0      0.112723        0.113372\n",
       "0        5.0              600.0      0.110576        0.109705\n",
       "0        5.0              800.0      0.109767        0.106242\n",
       "0        5.0              400.0      0.101381        0.119581\n",
       "0        7.0              800.0      0.088599        0.100746\n",
       "0        7.0             1000.0      0.086054        0.117424\n",
       "0        7.0              400.0      0.084912        0.095057\n",
       "0        7.0              200.0      0.084624        0.104247\n",
       "0        7.0              600.0      0.083532        0.093750"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=['max_depth','min_samples_split','CV F Measure','Test F Measure']\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "df_gb = pd.DataFrame( columns=columns)\n",
    "df_gb = df_gb.fillna(0) \n",
    "prob=0.5\n",
    "for max_depth in arange(5,15,2):\n",
    "    for min_samples_split in arange(200,1001,200):\n",
    "        sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)    \n",
    "        params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, 'min_samples_leaf':50,\\\n",
    "              'max_depth':max_depth, 'max_features':'sqrt', 'min_samples_split': min_samples_split}\n",
    "        clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "        df = pd.DataFrame([[max_depth,min_samples_split,over_cross_probability(clf,X_train,y_train,sm,prob),\\\n",
    "                            pred_prob(clf,X_test,y_test,prob)]],columns=columns)\n",
    "        df_gb=df_gb.append(df)\n",
    "        \n",
    "df_gb.sort_values(by=\"CV F Measure\",ascending=False).head(10)\n",
    "#max_depth=5\n",
    "#min_samples_split= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns=['min_samples_leaf','min_samples_split','CV F Measure','Test F Measure']\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "df_gb = pd.DataFrame( columns=columns)\n",
    "df_gb = df_gb.fillna(0) \n",
    "prob=0.5\n",
    "for min_samples_leaf in arange(30,71,10):\n",
    "    for min_samples_split in arange(200,1001,200):\n",
    "        sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)    \n",
    "        prob=0.5\n",
    "        params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':min_samples_leaf, 'max_depth':5, 'max_features':'sqrt', \\\n",
    "                  'min_samples_split': min_samples_split}\n",
    "        clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "        df = pd.DataFrame([[min_samples_leaf,min_samples_split,over_cross_probability(clf,X_train,y_train,sm,prob),\\\n",
    "                            pred_prob(clf,X_test,y_test,prob)]],columns=columns)\n",
    "        df_gb=df_gb.append(df)\n",
    "        \n",
    "df_gb.sort_values(by=\"CV F Measure\",ascending=False).head(10)\n",
    "#min_samples_split=400\n",
    "#min_samples_leaf=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_features</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.123419</td>\n",
       "      <td>0.136719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.117369</td>\n",
       "      <td>0.127049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.117167</td>\n",
       "      <td>0.122058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.116958</td>\n",
       "      <td>0.122862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.116652</td>\n",
       "      <td>0.122353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.116104</td>\n",
       "      <td>0.118565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.115625</td>\n",
       "      <td>0.123055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.115327</td>\n",
       "      <td>0.124551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.113932</td>\n",
       "      <td>0.128671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.113723</td>\n",
       "      <td>0.132132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_features  CV F Measure  Test F Measure\n",
       "0           7.0      0.123419        0.136719\n",
       "0           9.0      0.117369        0.127049\n",
       "0           6.0      0.117167        0.122058\n",
       "0           5.0      0.116958        0.122862\n",
       "0          11.0      0.116652        0.122353\n",
       "0           4.0      0.116104        0.118565\n",
       "0           3.0      0.115625        0.123055\n",
       "0          10.0      0.115327        0.124551\n",
       "0          14.0      0.113932        0.128671\n",
       "0           8.0      0.113723        0.132132"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max_features\n",
    "columns=['max_features','CV F Measure','Test F Measure']\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "df_gb = pd.DataFrame( columns=columns)\n",
    "df_gb = df_gb.fillna(0) \n",
    "prob=0.5\n",
    "for max_features in arange(2,26,1):\n",
    "    sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)\n",
    "    prob=0.5\n",
    "    params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':50, 'max_depth':5, 'max_features':'sqrt', \\\n",
    "                  'min_samples_split': 400,'max_features': max_features}\n",
    "    clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "    df = pd.DataFrame([[max_features,over_cross_probability(clf,X_train,y_train,sm,prob),\\\n",
    "                            pred_prob(clf,X_test,y_test,prob)]],columns=columns)\n",
    "    df_gb=df_gb.append(df)\n",
    "        \n",
    "df_gb.sort_values(by=\"CV F Measure\",ascending=False).head(10)\n",
    "#max_features=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.053211</td>\n",
       "      <td>0.054313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.085912</td>\n",
       "      <td>0.094874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.104766</td>\n",
       "      <td>0.113684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.116925</td>\n",
       "      <td>0.119075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.120907</td>\n",
       "      <td>0.121807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.094567</td>\n",
       "      <td>0.119403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.049887</td>\n",
       "      <td>0.064838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability  CV F Measure  Test F Measure\n",
       "0          0.1      0.053211        0.054313\n",
       "0          0.2      0.085912        0.094874\n",
       "0          0.3      0.104766        0.113684\n",
       "0          0.4      0.116925        0.119075\n",
       "0          0.5      0.120907        0.121807\n",
       "0          0.6      0.094567        0.119403\n",
       "0          0.7      0.049887        0.064838\n",
       "0          0.8      0.003213        0.000000\n",
       "0          0.9      0.000000        0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability for gradient boost\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_gb_prob = pd.DataFrame( columns=columns)\n",
    "df_gb_prob = df_gb_prob.fillna(0) \n",
    "sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)\n",
    "params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':50, 'max_depth':5 \\\n",
    "                  'min_samples_split': 400,'max_features': 7}\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "for prob in arange(0.1,1,0.1):\n",
    "    df = pd.DataFrame([[prob,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_gb_prob=df_gb_prob.append(df)\n",
    "    \n",
    "df_gb_prob\n",
    "#0.5 probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for - gradient boost\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_gb_prob = pd.DataFrame( columns=columns)\n",
    "df_gb_prob = df_gb_prob.fillna(0) \n",
    "sm = SMOTEENN()\n",
    "params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':50, 'max_depth':7, \\\n",
    "                  'min_samples_split': 400,'max_features': 7,'criterion':'make_scorer(f1_score,pos_label=1)'}\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "df = pd.DataFrame([[prob,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "df\n",
    "\n",
    "\n",
    "clf = GradientBoostingClassifier(**params).fit(X_norm, y)\n",
    "score,df_conf=cust_over_cm(clf,X_norm,y,prob,sm)\n",
    "letterone = df_conf.groupby(['Predictions','Actual'], as_index=False).size()\n",
    "letterone.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating Confusion Matrix\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "\n",
    "params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':50, 'max_depth':7, \\\n",
    "                  'min_samples_split': 400,'max_features': 7,'criterion':'make_scorer(f1_score,pos_label=1)'}\n",
    "\n",
    "clf = GradientBoostingClassifier(**params).fit(X_norm, y)\n",
    "score,df_conf=cust_over_cm(clf,X_norm,y,prob,sm)\n",
    "letterone = df_conf.groupby(['Predictions','Actual'], as_index=False).size()\n",
    "letterone.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xca4c518>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAAIcCAYAAADWs24AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1099fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating Best Features for original data\n",
    "X_norm = music.iloc[0:,:25].values\n",
    "predictors = music.iloc[0:,:25]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)\n",
    "\n",
    "X_train_oc, y_train_oc = sm.fit_sample(X_train, y_train)\n",
    "        \n",
    "\n",
    "params = {'n_estimators': 20,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':60, 'max_depth':7, \\\n",
    "                  'min_samples_split': 600}\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "colnames=predictors.columns.values\n",
    "\n",
    "df_imp_features=pd.DataFrame({'Column':colnames, 'Importance':importances})\n",
    "df_imp_features=df_imp_features.sort_values(by='Importance',ascending=False)\n",
    "\n",
    "df_imp_features = df_imp_features.reset_index(drop=True)\n",
    "#plt.bar(df_imp_features['Column'],df_imp_features['Importance'], color=\"r\")\n",
    "#plt.bar(df_imp_features.index,df_imp_features['Importance'], color=\"r\")\n",
    "LABELS = df_imp_features['Column']\n",
    "plt.bar(df_imp_features.index,df_imp_features['Importance'], color=\"r\")\n",
    "plt.xticks(df_imp_features.index, LABELS)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.suptitle('Gradient Boosting Feature Importance')\n",
    "#df_imp_features.head(45)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cut_features = df_imp_features[df_imp_features['Importance'] > 0.02]\n",
    "\n",
    "df_cut_features = df_cut_features.reset_index(drop=True)\n",
    "\n",
    "df_cut_features\n",
    "\n",
    "X_cut=predictors[df_cut_features[\"Column\"]]\n",
    "\n",
    "imp_features =X_cut.columns.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lovedTracks', 'delta_lovedTracks', 'subscriber_friend_cnt',\n",
       "       'avg_friend_age', 'delta_songsListened', 'age', 'shouts',\n",
       "       'playlists', 'tenure'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['delta_lovedTracks', 'subscriber_friend_cnt', 'playlists', 'age',\n",
       "       'delta_songsListened', 'lovedTracks'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_imp_features = predictors[imp_features]\n",
    "\n",
    "#X_imp_features.tail()\n",
    "\n",
    "X_norm = X_imp_features.values\n",
    "\n",
    "predictors = X_imp_features\n",
    "\n",
    "predictors.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.097958</td>\n",
       "      <td>0.104033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.109082</td>\n",
       "      <td>0.117040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.123830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability  CV F Measure  Test F Measure\n",
       "0          0.3      0.097958        0.104033\n",
       "0          0.4      0.109082        0.117040\n",
       "0          0.5      0.113611        0.123830"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradient boost for best features\n",
    "\n",
    "\n",
    "X_norm = X_imp_features.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_gb_prob = pd.DataFrame( columns=columns)\n",
    "df_gb_prob = df_gb_prob.fillna(0) \n",
    "#sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)\n",
    "sm = SMOTEENN(random_state = 0 )\n",
    "params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':40, 'max_depth':7, \\\n",
    "                  'min_samples_split': 200,'max_features': 'sqrt'}\n",
    "\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "for prob in arange(0.3,0.6,0.1):\n",
    "    df = pd.DataFrame([[prob,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_gb_prob=df_gb_prob.append(df)\n",
    "    \n",
    "df_gb_prob\n",
    "#0.5 probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>81428</td>\n",
       "      <td>1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3714</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual         0.0   1.0\n",
       "Predictions             \n",
       "0.0          81428  1213\n",
       "1.0           3714   327"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score,df_conf=cust_over_cm(clf,X_norm,y,0.5,sm)\n",
    "letterone = df_conf.groupby(['Predictions','Actual'], as_index=False).size()\n",
    "letterone.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10d8fcf8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAAH+CAYAAAC8184UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1c6588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating Best Features for over sampled data\n",
    "X_norm = X_imp_features.values\n",
    "predictors = X_imp_features\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "\n",
    "sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)\n",
    "\n",
    "X_train_oc, y_train_oc = sm.fit_sample(X_train, y_train)\n",
    "        \n",
    "\n",
    "params = {'n_estimators': 20,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':60, 'max_depth':7, \\\n",
    "                  'min_samples_split': 600}\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train_oc, y_train_oc)\n",
    "importances = clf.feature_importances_\n",
    "\n",
    "colnames=predictors.columns.values\n",
    "\n",
    "df_imp_features=pd.DataFrame({'Column':colnames, 'Importance':importances})\n",
    "df_imp_features=df_imp_features.sort_values(by='Importance',ascending=False)\n",
    "\n",
    "df_imp_features = df_imp_features.reset_index(drop=True)\n",
    "#plt.bar(df_imp_features['Column'],df_imp_features['Importance'], color=\"r\")\n",
    "#plt.bar(df_imp_features.index,df_imp_features['Importance'], color=\"r\")\n",
    "LABELS = df_imp_features['Column']\n",
    "plt.bar(df_imp_features.index,df_imp_features['Importance'], color=\"r\")\n",
    "plt.xticks(df_imp_features.index, LABELS)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.suptitle('Gradient Boosting Feature Importance')\n",
    "#df_imp_features.head(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate gradient boosting Output file\n",
    "X_val = test_music.iloc[0:,:25].values\n",
    "X_train = music.iloc[0:,:25].values\n",
    "y_train = y\n",
    "sm = SMOTEENN()\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':50, 'max_depth':7, 'max_features':'sqrt', \\\n",
    "                  'min_samples_split': 400,'max_features': 7}\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "predictions=clf.predict(X_val)\n",
    "#new_predictions = [0 if x <0.8 else 1 for x in predictions]\n",
    "df_out = pd.DataFrame(predictions, columns=['prediction(adopter)'])\n",
    "df_out=pd.concat([df_user,df_out], axis=1)\n",
    "df_out.to_csv(\"submit_gb.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99241806  0.9997896   0.99993009  0.99995907  0.99998542  0.99999578\n",
      "  0.99999893  0.99999936  0.99999975  0.99999987  0.99999993  0.99999996\n",
      "  0.99999998  0.99999999  1.        ]\n"
     ]
    }
   ],
   "source": [
    "X_train = music.iloc[0:,:25].values\n",
    "\n",
    "pca = PCA(n_components = 15,random_state=0)\n",
    "\n",
    "pca.fit(X_train)\n",
    "\n",
    "#print(pca.explained_variance_ratio_)\n",
    "print (pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86682L, 15L)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca = pca.transform(X_train)\n",
    "\n",
    "shape(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability</th>\n",
       "      <th>CV F Measure</th>\n",
       "      <th>Test F Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.063705</td>\n",
       "      <td>0.062861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.074723</td>\n",
       "      <td>0.075485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.085170</td>\n",
       "      <td>0.082375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability  CV F Measure  Test F Measure\n",
       "0          0.3      0.063705        0.062861\n",
       "0          0.4      0.074723        0.075485\n",
       "0          0.5      0.085170        0.082375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gradient boost using PCA\n",
    "\n",
    "X_norm = X_pca\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X_norm, y, test_size=0.2, random_state=0,stratify=y)\n",
    "columns=['Probability','CV F Measure','Test F Measure']\n",
    "df_gb_prob = pd.DataFrame( columns=columns)\n",
    "df_gb_prob = df_gb_prob.fillna(0) \n",
    "#sm= SMOTE(ratio = 0.4 , kind = 'borderline1', random_state = 0)\n",
    "sm = SMOTEENN(random_state = 0 )\n",
    "params = {'n_estimators': 40,  'learning_rate': 0.05, 'subsample': 0.8, 'random_state': 0, \\\n",
    "                  'min_samples_leaf':40, 'max_depth':7, \\\n",
    "                  'min_samples_split': 200,'max_features': 'sqrt'}\n",
    "\n",
    "clf = GradientBoostingClassifier(**params).fit(X_train, y_train)\n",
    "for prob in arange(0.3,0.6,0.1):\n",
    "    df = pd.DataFrame([[prob,over_cross_probability(clf,X_train,y_train,sm,prob),pred_prob(clf,X_test,y_test,prob)\\\n",
    "                       ]],columns=columns)\n",
    "    df_gb_prob=df_gb_prob.append(df)\n",
    "    \n",
    "df_gb_prob\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
